
# =======================================
# Google Colab Notebook: Image Enhancer
# Train a model to convert blurred images to enhanced ones
# =======================================

# ---- STEP 1: Install dependencies ----
!pip install -q tensorflow pillow matplotlib

import os
import zipfile
from pathlib import Path
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt

print("TensorFlow version:", tf.__version__)

# ---- STEP 2: Upload dataset manually ----
from google.colab import files

uploaded = files.upload()  # Upload your zip file (e.g., "Enchance dataset.zip")

zip_filename = list(uploaded.keys())[0]
dataset_path = "/content/dataset"

with zipfile.ZipFile(zip_filename, 'r') as zip_ref:
    zip_ref.extractall(dataset_path)

print("Extracted folders:", os.listdir(dataset_path))

# ---- STEP 3: Locate input and target folders ----
INPUT_CANDIDATES  = ["blurred", "blur", "input", "degraded"]
TARGET_CANDIDATES = ["enhanced", "clean", "target", "sharp"]

def find_subdir(root, candidates):
    root_p = Path(root)
    for name in candidates:
        for p in root_p.rglob("*"):
            if p.is_dir() and name.lower() in p.name.lower():
                return str(p)
    return None

inp_dir = find_subdir(dataset_path, INPUT_CANDIDATES)
tgt_dir = find_subdir(dataset_path, TARGET_CANDIDATES)

print("Input dir:", inp_dir)
print("Target dir:", tgt_dir)
assert inp_dir and tgt_dir, "Dataset subfolders not found!"

# ---- STEP 4: Data pipeline ----
IMG_SIZE = (128, 128)
BATCH_SIZE = 16

def load_images_from_folder(folder, size):
    images = []
    for fname in os.listdir(folder):
        path = os.path.join(folder, fname)
        try:
            img = tf.keras.utils.load_img(path, target_size=size)
            img = tf.keras.utils.img_to_array(img) / 255.0
            images.append(img)
        except:
            pass
    return np.array(images)

X = load_images_from_folder(inp_dir, IMG_SIZE)
Y = load_images_from_folder(tgt_dir, IMG_SIZE)

print("Input shape:", X.shape, "Target shape:", Y.shape)

# ---- STEP 5: Define model (simple U-Net style) ----
def build_unet(img_shape):
    inputs = layers.Input(shape=img_shape)

    # Encoder
    c1 = layers.Conv2D(64, (3,3), activation="relu", padding="same")(inputs)
    p1 = layers.MaxPooling2D((2,2))(c1)

    c2 = layers.Conv2D(128, (3,3), activation="relu", padding="same")(p1)
    p2 = layers.MaxPooling2D((2,2))(c2)

    c3 = layers.Conv2D(256, (3,3), activation="relu", padding="same")(p2)
    p3 = layers.MaxPooling2D((2,2))(c3)

    # Bottleneck
    bn = layers.Conv2D(512, (3,3), activation="relu", padding="same")(p3)

    # Decoder
    u1 = layers.UpSampling2D((2,2))(bn)
    concat1 = layers.Concatenate()([u1, c3])
    c4 = layers.Conv2D(256, (3,3), activation="relu", padding="same")(concat1)

    u2 = layers.UpSampling2D((2,2))(c4)
    concat2 = layers.Concatenate()([u2, c2])
    c5 = layers.Conv2D(128, (3,3), activation="relu", padding="same")(concat2)

    u3 = layers.UpSampling2D((2,2))(c5)
    concat3 = layers.Concatenate()([u3, c1])
    c6 = layers.Conv2D(64, (3,3), activation="relu", padding="same")(concat3)

    outputs = layers.Conv2D(3, (1,1), activation="sigmoid")(c6)

    model = models.Model(inputs, outputs)
    return model

model = build_unet((*IMG_SIZE, 3))
model.compile(optimizer="adam", loss="mse", metrics=["mae"])
model.summary()

# ---- STEP 6: Train ----
history = model.fit(X, Y, validation_split=0.1, epochs=20, batch_size=BATCH_SIZE)

# ---- STEP 7: Visualize predictions ----
preds = model.predict(X[:5])

plt.figure(figsize=(12,6))
for i in range(5):
    plt.subplot(3,5,i+1)
    plt.imshow(X[i])
    plt.axis("off")
    if i == 0: plt.ylabel("Input")

    plt.subplot(3,5,i+6)
    plt.imshow(preds[i])
    plt.axis("off")
    if i == 0: plt.ylabel("Predicted")

    plt.subplot(3,5,i+11)
    plt.imshow(Y[i])
    plt.axis("off")
    if i == 0: plt.ylabel("Target")
plt.show()
